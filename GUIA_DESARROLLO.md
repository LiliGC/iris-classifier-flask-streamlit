#  Gu铆a de Desarrollo y Evoluci贸n del Proyecto

Este documento narra el viaje de desarrollo del Clasificador de Iris, desde las pruebas manuales iniciales hasta la arquitectura final orquestada con Docker Compose. El objetivo es servir como una gu铆a de aprendizaje para entender las decisiones t茅cnicas tomadas en cada fase.

---

## Fase 0: Entrenamiento del Modelo de Machine Learning

Antes de que la aplicaci贸n pueda hacer predicciones, necesita un modelo entrenado. Este proceso se realiza una sola vez (o cada vez que se quiera actualizar el modelo) y se encapsula en el script `iris_app/model/train_model.py`.

### Proceso de Entrenamiento

El script sigue los pasos est谩ndar de un flujo de trabajo de Machine Learning:

1.  **Carga de Datos:** Se utiliza el dataset `iris` de Scikit-learn.
2.  **Divisi贸n de Datos:** El dataset se divide en conjuntos de entrenamiento y prueba.
3.  **Entrenamiento:** Se instancia y entrena un clasificador `RandomForestClassifier`.
4.  **Serializaci贸n (Guardado):** El modelo entrenado se guarda en un archivo `modelo.pkl` usando `joblib`. Esto permite que la API lo cargue r谩pidamente sin necesidad de reentrenar.
    ```python
    # iris_app/model/train_model.py
    joblib.dump(model, "iris_app/model/modelo.pkl")
    ```
![Entrenamiento del modelo](docs/images/train_model.png)

5.  **Generaci贸n de M茅tricas:** Se eval煤a el modelo con los datos de prueba y se guardan m茅tricas como `accuracy` y la matriz de confusi贸n en `metrics.json`.

### 驴C贸mo lo usa la API?

La API (`api/app.py`) est谩 dise帽ada para ser *stateless* en cuanto al entrenamiento. Simplemente carga el artefacto pre-entrenado (`modelo.pkl`) cuando se inicia.

```python
# iris_app/api/app.py
modelo = joblib.load("iris_app/model/modelo.pkl")
```

Este desacoplamiento es crucial: el entrenamiento es un proceso de desarrollo/investigaci贸n, mientras que la predicci贸n es una tarea de producci贸n.

## Fase 1: Desarrollo y Pruebas Manuales (Sin Docker)

El proyecto comenz贸 con dos scripts de Python independientes: uno para la API (`api/app.py`) y otro para el frontend (`frontend/frontend.py`).

### Ejecuci贸n

1.  **API (Flask):** Se ejecutaba directamente. El servidor de desarrollo de Flask es ideal para esta etapa.
    ```bash
    python iris_app/api/app.py
    ```
    *Salida esperada en la terminal:*

![Arranque manual de la API con Flask](docs/images/flask_app.png)

2.  **Frontend (Streamlit):** Se lanzaba en una terminal separada.
    ```bash
    streamlit run iris_app/frontend/frontend.py
    ```
    *Salida esperada en la terminal:*

![Arranque manual del frontend con Streamlit](docs/images/frontend_streamlit.png)

![Vista del frontend con Streamlit](docs/images/iris_streamlit.png)

    
### Pruebas Manuales de la API

Las primeras validaciones se hicieron con `curl` para asegurar que los endpoints respond铆an correctamente.

**Prueba de salud (`/health`):**
```bash
curl http://127.0.0.1:5000/health
# Respuesta esperada: {"status":"API funcionando","model":"Iris-RandomForest"}
```
![Respuesta del endpoint /health en cURL](docs/images/api_funcionando.png)

**Prueba de predicci贸n (`/predict`):**
```bash
curl -X POST http://127.0.0.1:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [5.1, 3.5, 1.4, 0.2]}'
# Respuesta esperada: {"prediction":0, "probabilities":[...]}
```
![Respuesta del endpoint /predict en cURL](docs/images/prueba_setosa.png)

**Prueba de predicci贸n con datos no v谩lidos(`/predict`):**
```bash
curl -X POST http://127.0.0.1:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [1, 2, 3, 4]}'
# Respuesta esperada: {"error":Datos mal estructurados"}
```
![Respuesta del endpoint /predict con datos no v谩lidos en cURL](docs/images/datos_invalidos.png)

**Limitaci贸n:** Este enfoque requiere que cada desarrollador configure su propio entorno de Python, instale dependencias manualmente y gestione dos procesos en terminales separadas. Es propenso a errores de "en mi m谩quina funciona".

**Prueba con el archivo test_api.py de la API:**
```bash
python iris_app/model/test_api.py
```
![Prueba con el archivo test_api.py de la API](docs/images/pruebas_api.png)

---

## Fase 2: Contenerizaci贸n Inicial con `Dockerfile` y `start.sh`

Para resolver el problema de la configuraci贸n del entorno, se introdujo Docker. El objetivo era empaquetar toda la aplicaci贸n en una sola imagen.

### El Desaf铆o: Dos Procesos, Un Contenedor

Un contenedor Docker est谩 dise帽ado para ejecutar un solo proceso principal. Para ejecutar tanto la API como el frontend, se cre贸 un script de shell (`start.sh`) que actuaba como punto de entrada.

```shell
#!/bin/bash
# Iniciar la API de Flask en segundo plano
waitress-serve --host=0.0.0.0 --port=5000 iris_app.api.app:app &

# Iniciar el frontend de Streamlit en primer plano
streamlit run iris_app/frontend/frontend.py --server.port=8501 --server.address=0.0.0.0
```

El `Dockerfile` se configur贸 para copiar este script y ejecutarlo con `CMD ["./start.sh"]`.

### Comandos de Docker

1.  **Construir la imagen:**
    ```bash
    docker build -t iris-classifier .
    ```

2.  **Ejecutar el contenedor:**
    ```bash
    docker run -p 5000:5000 -p 8501:8501 --name iris-app iris-classifier
    ```
![Ejecuci贸n del contenedor](docs/images/docker_run.png)

**Ventaja:** La aplicaci贸n ahora es portable. Cualquiera con Docker puede ejecutarla con dos comandos.

**Limitaciones:**
-   **Anti-patr贸n de Docker:** Va en contra de la filosof铆a de "un proceso por contenedor".
-   **Sin escalabilidad granular:** No se puede escalar la API sin escalar tambi茅n el frontend.
-   **Gesti贸n compleja:** Si la API falla, el contenedor podr铆a seguir funcionando, ocultando el problema.

---

## Fase 3: Orquestaci贸n Profesional con Docker Compose

Para superar las limitaciones anteriores y adoptar las mejores pr谩cticas, se introdujo `docker-compose`.

### La Soluci贸n: Servicios Separados

`docker-compose.yml` define la aplicaci贸n como un conjunto de **servicios** interconectados.

1.  **Servicio `api`:** Un contenedor que ejecuta 煤nicamente la API de Flask con `waitress`.
2.  **Servicio `frontend`:** Un segundo contenedor que ejecuta 煤nicamente Streamlit.

Docker Compose se encarga de:
-   **Construir la imagen** a partir del `Dockerfile` (que ya no necesita `start.sh`).
-   **Crear una red virtual** para que los contenedores se comuniquen entre s铆. El frontend puede llamar a la API usando su nombre de servicio (`http://api:5000`).
-   **Gestionar el ciclo de vida** de la aplicaci贸n con comandos simples.

### Comandos de Docker Compose

El flujo de trabajo se simplifica enormemente:
```bash
# Levantar toda la aplicaci贸n (construye si es necesario)
docker-compose up --build
```
![Comprobar si hay im谩genes de Docker construidas](docs/images/docker_images.png)

Ya que est谩n las im谩genes construidas, en futuras ejecuciones basta con:
```bash
docker-compose up
```
![Docker compose up para levantar la aplicaci贸n](docs/images/docker_composeup.png)

# Detener y eliminar todo
```bash
docker-compose down
```
![Docker compose down para detener la aplicaci贸n](docs/images/docker_composedown.png)

**Ventajas:**
-   **Alineado con las mejores pr谩cticas:** Un proceso por contenedor.
-   **Escalable y mantenible:** Cada parte de la aplicaci贸n es independiente.

Esta arquitectura final es robusta, profesional y est谩 lista para entornos de producci贸n.